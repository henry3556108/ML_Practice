{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 296 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       296 non-null    int64  \n",
      " 1   sex       296 non-null    int64  \n",
      " 2   cp        296 non-null    float64\n",
      " 3   trestbps  296 non-null    float64\n",
      " 4   chol      296 non-null    int64  \n",
      " 5   fbs       296 non-null    int64  \n",
      " 6   restecg   296 non-null    int64  \n",
      " 7   thalach   296 non-null    int64  \n",
      " 8   exang     296 non-null    int64  \n",
      " 9   oldpeak   296 non-null    float64\n",
      " 10  slope     296 non-null    int64  \n",
      " 11  ca        296 non-null    int64  \n",
      " 12  thal      296 non-null    int64  \n",
      " 13  target    296 non-null    int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 34.7 KB\n",
      "None\n",
      "   age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0   63    1  3.0     145.0   233    1        0      150      0      2.3   \n",
      "1   37    1  2.0     130.0   250    0        1      187      0      3.5   \n",
      "2   41    0  1.0     130.0   204    0        0      172      0      1.4   \n",
      "3   56    1  1.0     120.0   236    0        1      178      0      0.8   \n",
      "5   57    1  0.0     140.0   192    0        1      148      0      0.4   \n",
      "\n",
      "   slope  ca  thal  target  \n",
      "0      0   0     1       1  \n",
      "1      0   0     2       1  \n",
      "2      2   0     2       1  \n",
      "3      2   0     2       1  \n",
      "5      1   0     1       1  \n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "df = df.dropna(subset = [\"trestbps\", \"cp\"])\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sex   cp  fbs  restecg  exang  target\n",
      "0    1  3.0    1        0      0       1\n",
      "1    1  2.0    0        1      0       1\n",
      "2    0  1.0    0        0      0       1\n",
      "3    1  1.0    0        1      0       1\n",
      "5    1  0.0    0        1      0       1    age  trestbps  chol  thalach  oldpeak  slope  ca  thal\n",
      "0   63     145.0   233      150      2.3      0   0     1\n",
      "1   37     130.0   250      187      3.5      0   0     2\n",
      "2   41     130.0   204      172      1.4      2   0     2\n",
      "3   56     120.0   236      178      0.8      2   0     2\n",
      "5   57     140.0   192      148      0.4      1   0     1\n"
     ]
    }
   ],
   "source": [
    "category_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"target\"]\n",
    "category_data = df[category_columns]\n",
    "norm_data = df.drop(category_columns, axis = 1)\n",
    "print(category_data.head(), norm_data.head())\n",
    "# norm_data = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.069045</td>\n",
       "      <td>-0.980581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.267261</td>\n",
       "      <td>-0.392232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.336306</td>\n",
       "      <td>1.372813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c\n",
       "0 -1.224745 -1.069045 -0.980581\n",
       "1  0.000000 -0.267261 -0.392232\n",
       "2  1.224745  1.336306  1.372813"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def get_normalization_data(df):\n",
    "    scaler = StandardScaler()\n",
    "    d = scaler.fit_transform(df)\n",
    "    d = pd.DataFrame(d, columns = df.columns)\n",
    "    return d\n",
    "    \n",
    "test_df = pd.DataFrame([[1,1,1],[2,2,2], [3,4,5]], columns=[\"a\", \"b\", \"c\"])\n",
    "get_normalization_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  trestbps  chol  thalach  oldpeak  slope  ca  thal\n",
      "298   57     140.0   241      123      0.2      1   0     3\n",
      "299   45     110.0   264      132      1.2      1   0     3\n",
      "300   68     144.0   193      141      3.4      1   2     3\n",
      "301   57     130.0   131      115      1.2      1   1     3\n",
      "302   57     130.0   236      174      0.0      1   1     2\n",
      "          age  trestbps      chol   thalach   oldpeak     slope        ca  \\\n",
      "291  0.291897  0.478659 -0.093855 -1.166341 -0.720763 -0.646192 -0.717991   \n",
      "292 -1.030575 -1.224944  0.351728 -0.771032  0.136736 -0.646192 -0.717991   \n",
      "293  1.504162  0.705806 -1.023767 -0.375722  2.023236 -0.646192  1.231784   \n",
      "294  0.291897 -0.089209 -2.224904 -1.517727  0.136736 -0.646192  0.256896   \n",
      "295  0.291897 -0.089209 -0.190721  1.073746 -0.892263 -0.646192  0.256896   \n",
      "\n",
      "         thal  \n",
      "291  1.118706  \n",
      "292  1.118706  \n",
      "293  1.118706  \n",
      "294  1.118706  \n",
      "295 -0.520586  \n"
     ]
    }
   ],
   "source": [
    "print(norm_data.tail())\n",
    "norm_data = get_normalization_data(norm_data)\n",
    "print(norm_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  trestbps      chol   thalach   oldpeak     slope        ca  \\\n",
      "291  0.291897  0.478659 -0.093855 -1.166341 -0.720763 -0.646192 -0.717991   \n",
      "292 -1.030575 -1.224944  0.351728 -0.771032  0.136736 -0.646192 -0.717991   \n",
      "293  1.504162  0.705806 -1.023767 -0.375722  2.023236 -0.646192  1.231784   \n",
      "294  0.291897 -0.089209 -2.224904 -1.517727  0.136736 -0.646192  0.256896   \n",
      "295  0.291897 -0.089209 -0.190721  1.073746 -0.892263 -0.646192  0.256896   \n",
      "\n",
      "         thal  index  sex   cp  fbs  restecg  exang  \n",
      "291  1.118706    298    0  0.0    0        1      1  \n",
      "292  1.118706    299    1  3.0    0        1      0  \n",
      "293  1.118706    300    1  0.0    1        1      0  \n",
      "294  1.118706    301    1  0.0    0        1      1  \n",
      "295 -0.520586    302    0  1.0    0        0      0  \n"
     ]
    }
   ],
   "source": [
    "category_data = category_data.reset_index()\n",
    "df = pd.concat([norm_data, category_data], axis = 1)\n",
    "y = df[\"target\"]\n",
    "X = df.drop([\"target\"], axis = 1)\n",
    "print(X.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(data : \"X_train\"):\n",
    "\n",
    "    enter = Input(shape=(14,))\n",
    "    encoded = Dense(32, activation='relu')(enter)\n",
    "    encoded = Dense(8, activation='relu')(encoded)\n",
    "    encoder_output = Dense(4)(encoded)\n",
    "\n",
    "    decoded = Dense(8, activation='relu')(encoder_output)\n",
    "    decoded = Dense(32, activation='relu')(decoded)\n",
    "    decoded_output = Dense(14, activation='linear')(decoded)\n",
    "\n",
    "    autoencoder = Model(input=enter, output=decoded_output)\n",
    "\n",
    "    encoder = Model(input=enter, output=encoder_output)\n",
    "\n",
    "    earlystop = EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    autoencoder.fit(data, data,\n",
    "                    nb_epoch=2000,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[earlystop]\n",
    "                    )\n",
    "\n",
    "    encoded_data = encoder.predict(data)\n",
    "    return encoded_data\n",
    "\n",
    "\n",
    "def neural_network(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    NN_model = Sequential()\n",
    "\n",
    "    NN_model.add(Dense(X_train.shape[1], kernel_initializer='normal', kernel_regularizer=regularizers.l2(\n",
    "        0.001), input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    NN_model.add(Dense(64, kernel_initializer='normal',\n",
    "                       kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    NN_model.add(Dense(32, kernel_initializer='normal',\n",
    "                       kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    NN_model.add(Dense(8, kernel_initializer='normal',\n",
    "                       kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "\n",
    "    NN_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.03, decay=1e-6)\n",
    "    NN_model.compile(loss='mean_squared_error',\n",
    "                     optimizer=adam, metrics=['accuracy'])\n",
    "#     NN_model.summary()\n",
    "\n",
    "    earlystop = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "#     callbacks_list = [earlystop, checkpoint]\n",
    "\n",
    "    NN_model.fit(X_train, y_train, epochs=5000, batch_size=64,\n",
    "                           validation_split=0.33, callbacks=[earlystop])\n",
    "    pred = NN_model.predict(X_test)\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 45 samples\n",
      "Epoch 1/2000\n",
      "177/177 [==============================] - 0s 829us/step - loss: 2081.6786 - val_loss: 2996.0691\n",
      "Epoch 2/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 2017.1651 - val_loss: 2929.4958\n",
      "Epoch 3/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 1979.2717 - val_loss: 2886.9458\n",
      "Epoch 4/2000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 1951.2735 - val_loss: 2847.9043\n",
      "Epoch 5/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 1924.2241 - val_loss: 2809.8687\n",
      "Epoch 6/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 1899.2401 - val_loss: 2774.6692\n",
      "Epoch 7/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 1875.0097 - val_loss: 2736.6912\n",
      "Epoch 8/2000\n",
      "177/177 [==============================] - 0s 107us/step - loss: 1847.3072 - val_loss: 2694.1055\n",
      "Epoch 9/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 1817.4978 - val_loss: 2645.1956\n",
      "Epoch 10/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 1783.2633 - val_loss: 2589.0923\n",
      "Epoch 11/2000\n",
      "177/177 [==============================] - 0s 54us/step - loss: 1744.1476 - val_loss: 2524.7498\n",
      "Epoch 12/2000\n",
      "177/177 [==============================] - 0s 46us/step - loss: 1696.5172 - val_loss: 2450.7241\n",
      "Epoch 13/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 1645.8780 - val_loss: 2362.8545\n",
      "Epoch 14/2000\n",
      "177/177 [==============================] - 0s 68us/step - loss: 1581.6926 - val_loss: 2263.3901\n",
      "Epoch 15/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 1513.4031 - val_loss: 2151.2026\n",
      "Epoch 16/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 1431.1314 - val_loss: 2025.0186\n",
      "Epoch 17/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 1343.1798 - val_loss: 1882.7594\n",
      "Epoch 18/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 1244.6331 - val_loss: 1724.2922\n",
      "Epoch 19/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 1131.7058 - val_loss: 1546.0735\n",
      "Epoch 20/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 1008.6929 - val_loss: 1346.4669\n",
      "Epoch 21/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 869.1194 - val_loss: 1133.1921\n",
      "Epoch 22/2000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 721.5443 - val_loss: 911.6708\n",
      "Epoch 23/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 573.9103 - val_loss: 689.9299\n",
      "Epoch 24/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 419.7909 - val_loss: 481.2114\n",
      "Epoch 25/2000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 285.6266 - val_loss: 289.3508\n",
      "Epoch 26/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 161.0735 - val_loss: 132.7331\n",
      "Epoch 27/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 64.6379 - val_loss: 35.0921\n",
      "Epoch 28/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 13.9536 - val_loss: 2.3102\n",
      "Epoch 29/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 4.0812 - val_loss: 17.9612\n",
      "Epoch 30/2000\n",
      "177/177 [==============================] - ETA: 0s - loss: 13.19 - 0s 45us/step - loss: 19.0181 - val_loss: 42.9885\n",
      "Epoch 31/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 33.4007 - val_loss: 49.3026\n",
      "Epoch 32/2000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 32.7362 - val_loss: 35.3247\n",
      "Epoch 33/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 21.2431 - val_loss: 17.0175\n",
      "Epoch 34/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 9.6901 - val_loss: 4.8147\n",
      "Epoch 35/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 2.6007 - val_loss: 1.0834\n",
      "Epoch 36/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 1.0995 - val_loss: 2.5934\n",
      "Epoch 37/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 2.4308 - val_loss: 5.1650\n",
      "Epoch 38/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 3.7751 - val_loss: 6.2203\n",
      "Epoch 39/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 4.1013 - val_loss: 5.4382\n",
      "Epoch 40/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 3.3475 - val_loss: 3.6545\n",
      "Epoch 41/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 2.1953 - val_loss: 1.9699\n",
      "Epoch 42/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 1.2576 - val_loss: 1.0241\n",
      "Epoch 43/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.8638 - val_loss: 0.7784\n",
      "Epoch 44/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8792 - val_loss: 0.9510\n",
      "Epoch 45/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 1.0514 - val_loss: 1.1043\n",
      "Epoch 46/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 1.1569 - val_loss: 1.0997\n",
      "Epoch 47/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 1.1053 - val_loss: 0.9807\n",
      "Epoch 48/2000\n",
      "177/177 [==============================] - 0s 44us/step - loss: 0.9769 - val_loss: 0.8161\n",
      "Epoch 49/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.8621 - val_loss: 0.7625\n",
      "Epoch 50/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8119 - val_loss: 0.8129\n",
      "Epoch 51/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.8198 - val_loss: 0.8572\n",
      "Epoch 52/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8414 - val_loss: 0.8902\n",
      "Epoch 53/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.8514 - val_loss: 0.9040\n",
      "Epoch 54/2000\n",
      "177/177 [==============================] - 0s 62us/step - loss: 0.8432 - val_loss: 0.8559\n",
      "Epoch 55/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8274 - val_loss: 0.8053\n",
      "Epoch 56/2000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.8122 - val_loss: 0.8064\n",
      "Epoch 57/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8097 - val_loss: 0.7772\n",
      "Epoch 58/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8090 - val_loss: 0.7552\n",
      "Epoch 59/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.8107 - val_loss: 0.7809\n",
      "Epoch 60/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8124 - val_loss: 0.7644\n",
      "Epoch 61/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8118 - val_loss: 0.7610\n",
      "Epoch 62/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8078 - val_loss: 0.7942\n",
      "Epoch 63/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8028 - val_loss: 0.7721\n",
      "Epoch 64/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8101 - val_loss: 0.7719\n",
      "Epoch 65/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.8071 - val_loss: 0.8034\n",
      "Epoch 66/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8016 - val_loss: 0.7686\n",
      "Epoch 67/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8019 - val_loss: 0.7705\n",
      "Epoch 68/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8000 - val_loss: 0.7822\n",
      "Epoch 69/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.8005 - val_loss: 0.7621\n",
      "Epoch 70/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8061 - val_loss: 0.7696\n",
      "Epoch 71/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8004 - val_loss: 0.7759\n",
      "Epoch 72/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7992 - val_loss: 0.7611\n",
      "Epoch 73/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.8022 - val_loss: 0.7658\n",
      "Epoch 74/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7981 - val_loss: 0.7698\n",
      "Epoch 75/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7981 - val_loss: 0.7632\n",
      "Epoch 76/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7962 - val_loss: 0.7792\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 51us/step - loss: 0.7943 - val_loss: 0.7619\n",
      "Epoch 78/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7966 - val_loss: 0.7525\n",
      "Epoch 79/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7928 - val_loss: 0.7795\n",
      "Epoch 80/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7947 - val_loss: 0.7644\n",
      "Epoch 81/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7910 - val_loss: 0.7535\n",
      "Epoch 82/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7876 - val_loss: 0.7599\n",
      "Epoch 83/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7964 - val_loss: 0.7666\n",
      "Epoch 84/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7954 - val_loss: 0.7418\n",
      "Epoch 85/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7882 - val_loss: 0.7601\n",
      "Epoch 86/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7915 - val_loss: 0.7547\n",
      "Epoch 87/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7848 - val_loss: 0.7378\n",
      "Epoch 88/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7846 - val_loss: 0.7454\n",
      "Epoch 89/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.7781 - val_loss: 0.7448\n",
      "Epoch 90/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7792 - val_loss: 0.7404\n",
      "Epoch 91/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7752 - val_loss: 0.7398\n",
      "Epoch 92/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7760 - val_loss: 0.7286\n",
      "Epoch 93/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7731 - val_loss: 0.7342\n",
      "Epoch 94/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7734 - val_loss: 0.7352\n",
      "Epoch 95/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7694 - val_loss: 0.7301\n",
      "Epoch 96/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7770 - val_loss: 0.7149\n",
      "Epoch 97/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7641 - val_loss: 0.7466\n",
      "Epoch 98/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7750 - val_loss: 0.7217\n",
      "Epoch 99/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7688 - val_loss: 0.7134\n",
      "Epoch 100/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7645 - val_loss: 0.7360\n",
      "Epoch 101/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7649 - val_loss: 0.7204\n",
      "Epoch 102/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7598 - val_loss: 0.7031\n",
      "Epoch 103/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7628 - val_loss: 0.7096\n",
      "Epoch 104/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7586 - val_loss: 0.7259\n",
      "Epoch 105/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7576 - val_loss: 0.7046\n",
      "Epoch 106/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7572 - val_loss: 0.7065\n",
      "Epoch 107/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7555 - val_loss: 0.7153\n",
      "Epoch 108/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7554 - val_loss: 0.6944\n",
      "Epoch 109/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7550 - val_loss: 0.6971\n",
      "Epoch 110/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7517 - val_loss: 0.7140\n",
      "Epoch 111/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7489 - val_loss: 0.6930\n",
      "Epoch 112/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7494 - val_loss: 0.6950\n",
      "Epoch 113/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7429 - val_loss: 0.6975\n",
      "Epoch 114/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7476 - val_loss: 0.6970\n",
      "Epoch 115/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7424 - val_loss: 0.6838\n",
      "Epoch 116/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7423 - val_loss: 0.6847\n",
      "Epoch 117/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.7405 - val_loss: 0.6960\n",
      "Epoch 118/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7345 - val_loss: 0.6706\n",
      "Epoch 119/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7299 - val_loss: 0.6662\n",
      "Epoch 120/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.7319 - val_loss: 0.6526\n",
      "Epoch 121/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7227 - val_loss: 0.6647\n",
      "Epoch 122/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7270 - val_loss: 0.6430\n",
      "Epoch 123/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7183 - val_loss: 0.6416\n",
      "Epoch 124/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7236 - val_loss: 0.6435\n",
      "Epoch 125/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7192 - val_loss: 0.6304\n",
      "Epoch 126/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7155 - val_loss: 0.6397\n",
      "Epoch 127/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7078 - val_loss: 0.6324\n",
      "Epoch 128/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7061 - val_loss: 0.6305\n",
      "Epoch 129/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7052 - val_loss: 0.6232\n",
      "Epoch 130/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7004 - val_loss: 0.6345\n",
      "Epoch 131/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6981 - val_loss: 0.6165\n",
      "Epoch 132/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6973 - val_loss: 0.6150\n",
      "Epoch 133/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.7003 - val_loss: 0.6229\n",
      "Epoch 134/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.7001 - val_loss: 0.6183\n",
      "Epoch 135/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.7004 - val_loss: 0.6226\n",
      "Epoch 136/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6952 - val_loss: 0.6094\n",
      "Epoch 137/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6977 - val_loss: 0.6231\n",
      "Epoch 138/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6935 - val_loss: 0.6156\n",
      "Epoch 139/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6985 - val_loss: 0.6010\n",
      "Epoch 140/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6918 - val_loss: 0.6225\n",
      "Epoch 141/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6878 - val_loss: 0.6104\n",
      "Epoch 142/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6899 - val_loss: 0.6100\n",
      "Epoch 143/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6919 - val_loss: 0.6137\n",
      "Epoch 144/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6917 - val_loss: 0.5994\n",
      "Epoch 145/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.6832 - val_loss: 0.6062\n",
      "Epoch 146/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6808 - val_loss: 0.6100\n",
      "Epoch 147/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6797 - val_loss: 0.5890\n",
      "Epoch 148/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6771 - val_loss: 0.5881\n",
      "Epoch 149/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6741 - val_loss: 0.6036\n",
      "Epoch 150/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6733 - val_loss: 0.5945\n",
      "Epoch 151/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6745 - val_loss: 0.5821\n",
      "Epoch 152/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6735 - val_loss: 0.5983\n",
      "Epoch 153/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6712 - val_loss: 0.5899\n",
      "Epoch 154/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6739 - val_loss: 0.5856\n",
      "Epoch 155/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 40us/step - loss: 0.6676 - val_loss: 0.5978\n",
      "Epoch 156/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6713 - val_loss: 0.5841\n",
      "Epoch 157/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6715 - val_loss: 0.5886\n",
      "Epoch 158/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6661 - val_loss: 0.5924\n",
      "Epoch 159/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6668 - val_loss: 0.5806\n",
      "Epoch 160/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6751 - val_loss: 0.5816\n",
      "Epoch 161/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6677 - val_loss: 0.5940\n",
      "Epoch 162/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6668 - val_loss: 0.5860\n",
      "Epoch 163/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6705 - val_loss: 0.5761\n",
      "Epoch 164/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6574 - val_loss: 0.6085\n",
      "Epoch 165/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6619 - val_loss: 0.5756\n",
      "Epoch 166/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6598 - val_loss: 0.5696\n",
      "Epoch 167/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6584 - val_loss: 0.5839\n",
      "Epoch 168/2000\n",
      "177/177 [==============================] - 0s 47us/step - loss: 0.6596 - val_loss: 0.5790\n",
      "Epoch 169/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6565 - val_loss: 0.5734\n",
      "Epoch 170/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6542 - val_loss: 0.5751\n",
      "Epoch 171/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6533 - val_loss: 0.5774\n",
      "Epoch 172/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6519 - val_loss: 0.5710\n",
      "Epoch 173/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6551 - val_loss: 0.5688\n",
      "Epoch 174/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6522 - val_loss: 0.5734\n",
      "Epoch 175/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6484 - val_loss: 0.5742\n",
      "Epoch 176/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6462 - val_loss: 0.5663\n",
      "Epoch 177/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6443 - val_loss: 0.5644\n",
      "Epoch 178/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6421 - val_loss: 0.5623\n",
      "Epoch 179/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6458 - val_loss: 0.5676\n",
      "Epoch 180/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6390 - val_loss: 0.5709\n",
      "Epoch 181/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6425 - val_loss: 0.5601\n",
      "Epoch 182/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6368 - val_loss: 0.5635\n",
      "Epoch 183/2000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.654 - 0s 51us/step - loss: 0.6380 - val_loss: 0.5548\n",
      "Epoch 184/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6345 - val_loss: 0.5547\n",
      "Epoch 185/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6347 - val_loss: 0.5610\n",
      "Epoch 186/2000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.6312 - val_loss: 0.5593\n",
      "Epoch 187/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6333 - val_loss: 0.5511\n",
      "Epoch 188/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.6305 - val_loss: 0.5716\n",
      "Epoch 189/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6304 - val_loss: 0.5522\n",
      "Epoch 190/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6295 - val_loss: 0.5493\n",
      "Epoch 191/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6274 - val_loss: 0.5648\n",
      "Epoch 192/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6237 - val_loss: 0.5521\n",
      "Epoch 193/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6248 - val_loss: 0.5411\n",
      "Epoch 194/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6162 - val_loss: 0.5596\n",
      "Epoch 195/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.6166 - val_loss: 0.5375\n",
      "Epoch 196/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6168 - val_loss: 0.5379\n",
      "Epoch 197/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.6098 - val_loss: 0.5544\n",
      "Epoch 198/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6117 - val_loss: 0.5335\n",
      "Epoch 199/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.6067 - val_loss: 0.5266\n",
      "Epoch 200/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.6000 - val_loss: 0.5349\n",
      "Epoch 201/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.5950 - val_loss: 0.5291\n",
      "Epoch 202/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.5930 - val_loss: 0.5303\n",
      "Epoch 203/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5897 - val_loss: 0.5215\n",
      "Epoch 204/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.5884 - val_loss: 0.5154\n",
      "Epoch 205/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5837 - val_loss: 0.5136\n",
      "Epoch 206/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.5820 - val_loss: 0.5234\n",
      "Epoch 207/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5824 - val_loss: 0.5049\n",
      "Epoch 208/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.5763 - val_loss: 0.5103\n",
      "Epoch 209/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5715 - val_loss: 0.5157\n",
      "Epoch 210/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.5653 - val_loss: 0.5025\n",
      "Epoch 211/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5597 - val_loss: 0.5122\n",
      "Epoch 212/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5652 - val_loss: 0.4996\n",
      "Epoch 213/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5621 - val_loss: 0.5025\n",
      "Epoch 214/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.5539 - val_loss: 0.5094\n",
      "Epoch 215/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5620 - val_loss: 0.4982\n",
      "Epoch 216/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5601 - val_loss: 0.5034\n",
      "Epoch 217/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5464 - val_loss: 0.5004\n",
      "Epoch 218/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5410 - val_loss: 0.5265\n",
      "Epoch 219/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.5377 - val_loss: 0.4841\n",
      "Epoch 220/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.5389 - val_loss: 0.5165\n",
      "Epoch 221/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5384 - val_loss: 0.4791\n",
      "Epoch 222/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.5313 - val_loss: 0.4955\n",
      "Epoch 223/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5291 - val_loss: 0.4968\n",
      "Epoch 224/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5199 - val_loss: 0.4604\n",
      "Epoch 225/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5180 - val_loss: 0.4819\n",
      "Epoch 226/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5117 - val_loss: 0.4703\n",
      "Epoch 227/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5106 - val_loss: 0.4740\n",
      "Epoch 228/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5035 - val_loss: 0.4655\n",
      "Epoch 229/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.5017 - val_loss: 0.4874\n",
      "Epoch 230/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.5048 - val_loss: 0.4586\n",
      "Epoch 231/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4952 - val_loss: 0.4704\n",
      "Epoch 232/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4956 - val_loss: 0.4541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4943 - val_loss: 0.4534\n",
      "Epoch 234/2000\n",
      "177/177 [==============================] - 0s 28us/step - loss: 0.4893 - val_loss: 0.4673\n",
      "Epoch 235/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4871 - val_loss: 0.4527\n",
      "Epoch 236/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4879 - val_loss: 0.4553\n",
      "Epoch 237/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4823 - val_loss: 0.4449\n",
      "Epoch 238/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4797 - val_loss: 0.4432\n",
      "Epoch 239/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4773 - val_loss: 0.4316\n",
      "Epoch 240/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4828 - val_loss: 0.4555\n",
      "Epoch 241/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4763 - val_loss: 0.4327\n",
      "Epoch 242/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4702 - val_loss: 0.4323\n",
      "Epoch 243/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4693 - val_loss: 0.4459\n",
      "Epoch 244/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4704 - val_loss: 0.4200\n",
      "Epoch 245/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4705 - val_loss: 0.4372\n",
      "Epoch 246/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4681 - val_loss: 0.4242\n",
      "Epoch 247/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4689 - val_loss: 0.4214\n",
      "Epoch 248/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4655 - val_loss: 0.4612\n",
      "Epoch 249/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4672 - val_loss: 0.4160\n",
      "Epoch 250/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4752 - val_loss: 0.4097\n",
      "Epoch 251/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4606 - val_loss: 0.4173\n",
      "Epoch 252/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.4596 - val_loss: 0.4169\n",
      "Epoch 253/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4537 - val_loss: 0.4126\n",
      "Epoch 254/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4526 - val_loss: 0.3993\n",
      "Epoch 255/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4457 - val_loss: 0.4287\n",
      "Epoch 256/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4482 - val_loss: 0.3936\n",
      "Epoch 257/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4456 - val_loss: 0.4171\n",
      "Epoch 258/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4433 - val_loss: 0.3985\n",
      "Epoch 259/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4427 - val_loss: 0.3958\n",
      "Epoch 260/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4434 - val_loss: 0.3944\n",
      "Epoch 261/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4372 - val_loss: 0.4039\n",
      "Epoch 262/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4401 - val_loss: 0.3911\n",
      "Epoch 263/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4405 - val_loss: 0.3895\n",
      "Epoch 264/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4346 - val_loss: 0.3907\n",
      "Epoch 265/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4368 - val_loss: 0.3957\n",
      "Epoch 266/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4372 - val_loss: 0.3809\n",
      "Epoch 267/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4306 - val_loss: 0.3987\n",
      "Epoch 268/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4357 - val_loss: 0.4011\n",
      "Epoch 269/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4347 - val_loss: 0.3812\n",
      "Epoch 270/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4341 - val_loss: 0.3941\n",
      "Epoch 271/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4345 - val_loss: 0.3943\n",
      "Epoch 272/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4330 - val_loss: 0.3943\n",
      "Epoch 273/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4351 - val_loss: 0.3777\n",
      "Epoch 274/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4338 - val_loss: 0.4331\n",
      "Epoch 275/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4442 - val_loss: 0.3797\n",
      "Epoch 276/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4338 - val_loss: 0.4157\n",
      "Epoch 277/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4369 - val_loss: 0.3914\n",
      "Epoch 278/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4389 - val_loss: 0.3873\n",
      "Epoch 279/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4311 - val_loss: 0.3790\n",
      "Epoch 280/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4342 - val_loss: 0.3837\n",
      "Epoch 281/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4348 - val_loss: 0.3983\n",
      "Epoch 282/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4309 - val_loss: 0.3884\n",
      "Epoch 283/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4289 - val_loss: 0.3935\n",
      "Epoch 284/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4347 - val_loss: 0.3899\n",
      "Epoch 285/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4305 - val_loss: 0.4031\n",
      "Epoch 286/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4303 - val_loss: 0.3792\n",
      "Epoch 287/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4241 - val_loss: 0.4032\n",
      "Epoch 288/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4304 - val_loss: 0.3878\n",
      "Epoch 289/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4293 - val_loss: 0.3784\n",
      "Epoch 290/2000\n",
      "177/177 [==============================] - 0s 28us/step - loss: 0.4312 - val_loss: 0.3788\n",
      "Epoch 291/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4223 - val_loss: 0.4090\n",
      "Epoch 292/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4274 - val_loss: 0.3749\n",
      "Epoch 293/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4297 - val_loss: 0.3774\n",
      "Epoch 294/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4248 - val_loss: 0.3901\n",
      "Epoch 295/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4248 - val_loss: 0.3725\n",
      "Epoch 296/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4277 - val_loss: 0.3946\n",
      "Epoch 297/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4287 - val_loss: 0.3830\n",
      "Epoch 298/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4257 - val_loss: 0.3828\n",
      "Epoch 299/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4234 - val_loss: 0.3748\n",
      "Epoch 300/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4212 - val_loss: 0.3899\n",
      "Epoch 301/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4198 - val_loss: 0.3712\n",
      "Epoch 302/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4247 - val_loss: 0.3800\n",
      "Epoch 303/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4205 - val_loss: 0.3850\n",
      "Epoch 304/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4193 - val_loss: 0.3791\n",
      "Epoch 305/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4212 - val_loss: 0.3757\n",
      "Epoch 306/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4170 - val_loss: 0.3794\n",
      "Epoch 307/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4196 - val_loss: 0.3836\n",
      "Epoch 308/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4201 - val_loss: 0.3733\n",
      "Epoch 309/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4171 - val_loss: 0.3789\n",
      "Epoch 310/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4166 - val_loss: 0.3757\n",
      "Epoch 311/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 40us/step - loss: 0.4165 - val_loss: 0.3727\n",
      "Epoch 312/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4166 - val_loss: 0.3753\n",
      "Epoch 313/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4180 - val_loss: 0.3783\n",
      "Epoch 314/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4169 - val_loss: 0.3823\n",
      "Epoch 315/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4187 - val_loss: 0.3806\n",
      "Epoch 316/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4230 - val_loss: 0.3746\n",
      "Epoch 317/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4198 - val_loss: 0.3931\n",
      "Epoch 318/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4219 - val_loss: 0.3761\n",
      "Epoch 319/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4207 - val_loss: 0.3854\n",
      "Epoch 320/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4196 - val_loss: 0.3877\n",
      "Epoch 321/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4175 - val_loss: 0.3820\n",
      "Epoch 322/2000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.386 - 0s 45us/step - loss: 0.4156 - val_loss: 0.3722\n",
      "Epoch 323/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4156 - val_loss: 0.3832\n",
      "Epoch 324/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4145 - val_loss: 0.3700\n",
      "Epoch 325/2000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.431 - 0s 45us/step - loss: 0.4144 - val_loss: 0.3812\n",
      "Epoch 326/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4140 - val_loss: 0.3635\n",
      "Epoch 327/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4195 - val_loss: 0.3832\n",
      "Epoch 328/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4144 - val_loss: 0.3883\n",
      "Epoch 329/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4168 - val_loss: 0.3771\n",
      "Epoch 330/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4203 - val_loss: 0.3683\n",
      "Epoch 331/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4169 - val_loss: 0.3933\n",
      "Epoch 332/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4169 - val_loss: 0.3802\n",
      "Epoch 333/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4192 - val_loss: 0.3683\n",
      "Epoch 334/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4123 - val_loss: 0.3821\n",
      "Epoch 335/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4191 - val_loss: 0.3752\n",
      "Epoch 336/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4094 - val_loss: 0.3906\n",
      "Epoch 337/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4147 - val_loss: 0.3660\n",
      "Epoch 338/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4113 - val_loss: 0.3913\n",
      "Epoch 339/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4147 - val_loss: 0.3749\n",
      "Epoch 340/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4116 - val_loss: 0.3819\n",
      "Epoch 341/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4141 - val_loss: 0.3783\n",
      "Epoch 342/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4133 - val_loss: 0.3790\n",
      "Epoch 343/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4113 - val_loss: 0.3680\n",
      "Epoch 344/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4093 - val_loss: 0.3725\n",
      "Epoch 345/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4110 - val_loss: 0.3818\n",
      "Epoch 346/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4089 - val_loss: 0.3715\n",
      "Epoch 347/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4090 - val_loss: 0.3773\n",
      "Epoch 348/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4085 - val_loss: 0.3760\n",
      "Epoch 349/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4083 - val_loss: 0.3723\n",
      "Epoch 350/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4101 - val_loss: 0.3701\n",
      "Epoch 351/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4089 - val_loss: 0.3801\n",
      "Epoch 352/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4073 - val_loss: 0.3682\n",
      "Epoch 353/2000\n",
      "177/177 [==============================] - 0s 28us/step - loss: 0.4072 - val_loss: 0.3790\n",
      "Epoch 354/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4068 - val_loss: 0.3666\n",
      "Epoch 355/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4071 - val_loss: 0.3749\n",
      "Epoch 356/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4044 - val_loss: 0.3681\n",
      "Epoch 357/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4080 - val_loss: 0.3684\n",
      "Epoch 358/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4052 - val_loss: 0.3780\n",
      "Epoch 359/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4080 - val_loss: 0.3701\n",
      "Epoch 360/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4056 - val_loss: 0.3807\n",
      "Epoch 361/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4086 - val_loss: 0.3736\n",
      "Epoch 362/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4043 - val_loss: 0.3720\n",
      "Epoch 363/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4042 - val_loss: 0.3747\n",
      "Epoch 364/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4064 - val_loss: 0.3757\n",
      "Epoch 365/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4046 - val_loss: 0.3678\n",
      "Epoch 366/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4034 - val_loss: 0.3977\n",
      "Epoch 367/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4036 - val_loss: 0.3685\n",
      "Epoch 368/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4087 - val_loss: 0.3973\n",
      "Epoch 369/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4087 - val_loss: 0.3777\n",
      "Epoch 370/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4122 - val_loss: 0.3819\n",
      "Epoch 371/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4088 - val_loss: 0.3783\n",
      "Epoch 372/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4027 - val_loss: 0.3729\n",
      "Epoch 373/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.4031 - val_loss: 0.3819\n",
      "Epoch 374/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4038 - val_loss: 0.3810\n",
      "Epoch 375/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4031 - val_loss: 0.3630\n",
      "Epoch 376/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4001 - val_loss: 0.3744\n",
      "Epoch 377/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4030 - val_loss: 0.3794\n",
      "Epoch 378/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4018 - val_loss: 0.3669\n",
      "Epoch 379/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4060 - val_loss: 0.3879\n",
      "Epoch 380/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4004 - val_loss: 0.3743\n",
      "Epoch 381/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4002 - val_loss: 0.3809\n",
      "Epoch 382/2000\n",
      "177/177 [==============================] - 0s 56us/step - loss: 0.4039 - val_loss: 0.3721\n",
      "Epoch 383/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3996 - val_loss: 0.3736\n",
      "Epoch 384/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4012 - val_loss: 0.3697\n",
      "Epoch 385/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4022 - val_loss: 0.3685\n",
      "Epoch 386/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4005 - val_loss: 0.3715\n",
      "Epoch 387/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3979 - val_loss: 0.3854\n",
      "Epoch 388/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 0s 34us/step - loss: 0.4003 - val_loss: 0.3723\n",
      "Epoch 389/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4092 - val_loss: 0.3705\n",
      "Epoch 390/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4055 - val_loss: 0.3872\n",
      "Epoch 391/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3985 - val_loss: 0.3608\n",
      "Epoch 392/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3982 - val_loss: 0.3885\n",
      "Epoch 393/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4040 - val_loss: 0.3697\n",
      "Epoch 394/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4005 - val_loss: 0.3680\n",
      "Epoch 395/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3954 - val_loss: 0.3798\n",
      "Epoch 396/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4018 - val_loss: 0.3693\n",
      "Epoch 397/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3970 - val_loss: 0.3762\n",
      "Epoch 398/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3960 - val_loss: 0.3689\n",
      "Epoch 399/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3960 - val_loss: 0.3802\n",
      "Epoch 400/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3987 - val_loss: 0.3657\n",
      "Epoch 401/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3962 - val_loss: 0.3658\n",
      "Epoch 402/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4021 - val_loss: 0.3856\n",
      "Epoch 403/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.4082 - val_loss: 0.3631\n",
      "Epoch 404/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3997 - val_loss: 0.3843\n",
      "Epoch 405/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3939 - val_loss: 0.3659\n",
      "Epoch 406/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.4015 - val_loss: 0.3813\n",
      "Epoch 407/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3997 - val_loss: 0.3705\n",
      "Epoch 408/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.4039 - val_loss: 0.3894\n",
      "Epoch 409/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3963 - val_loss: 0.3723\n",
      "Epoch 410/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3963 - val_loss: 0.3815\n",
      "Epoch 411/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3959 - val_loss: 0.3699\n",
      "Epoch 412/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3973 - val_loss: 0.3658\n",
      "Epoch 413/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3941 - val_loss: 0.3852\n",
      "Epoch 414/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3967 - val_loss: 0.3604\n",
      "Epoch 415/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.4008 - val_loss: 0.3777\n",
      "Epoch 416/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3898 - val_loss: 0.3837\n",
      "Epoch 417/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3994 - val_loss: 0.3590\n",
      "Epoch 418/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3949 - val_loss: 0.3827\n",
      "Epoch 419/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3971 - val_loss: 0.3714\n",
      "Epoch 420/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3999 - val_loss: 0.3682\n",
      "Epoch 421/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3949 - val_loss: 0.3728\n",
      "Epoch 422/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3958 - val_loss: 0.3612\n",
      "Epoch 423/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.3903 - val_loss: 0.3829\n",
      "Epoch 424/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3928 - val_loss: 0.3615\n",
      "Epoch 425/2000\n",
      "177/177 [==============================] - 0s 51us/step - loss: 0.3887 - val_loss: 0.3767\n",
      "Epoch 426/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3915 - val_loss: 0.3665\n",
      "Epoch 427/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3913 - val_loss: 0.3661\n",
      "Epoch 428/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3905 - val_loss: 0.3643\n",
      "Epoch 429/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3870 - val_loss: 0.3857\n",
      "Epoch 430/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3924 - val_loss: 0.3598\n",
      "Epoch 431/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3875 - val_loss: 0.3696\n",
      "Epoch 432/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3921 - val_loss: 0.3747\n",
      "Epoch 433/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3893 - val_loss: 0.3745\n",
      "Epoch 434/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3914 - val_loss: 0.3646\n",
      "Epoch 435/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3864 - val_loss: 0.3853\n",
      "Epoch 436/2000\n",
      "177/177 [==============================] - ETA: 0s - loss: 0.377 - 0s 45us/step - loss: 0.3898 - val_loss: 0.3621\n",
      "Epoch 437/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3915 - val_loss: 0.3665\n",
      "Epoch 438/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3878 - val_loss: 0.3709\n",
      "Epoch 439/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3920 - val_loss: 0.3670\n",
      "Epoch 440/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3857 - val_loss: 0.3726\n",
      "Epoch 441/2000\n",
      "177/177 [==============================] - 0s 39us/step - loss: 0.3905 - val_loss: 0.3822\n",
      "Epoch 442/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3891 - val_loss: 0.3597\n",
      "Epoch 443/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3855 - val_loss: 0.3724\n",
      "Epoch 444/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3858 - val_loss: 0.3684\n",
      "Epoch 445/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3889 - val_loss: 0.3725\n",
      "Epoch 446/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3878 - val_loss: 0.3594\n",
      "Epoch 447/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3858 - val_loss: 0.3752\n",
      "Epoch 448/2000\n",
      "177/177 [==============================] - 0s 79us/step - loss: 0.3893 - val_loss: 0.3817\n",
      "Epoch 449/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3897 - val_loss: 0.3593\n",
      "Epoch 450/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3880 - val_loss: 0.3681\n",
      "Epoch 451/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3835 - val_loss: 0.3744\n",
      "Epoch 452/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3848 - val_loss: 0.3672\n",
      "Epoch 453/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3884 - val_loss: 0.3635\n",
      "Epoch 454/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3832 - val_loss: 0.3783\n",
      "Epoch 455/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3872 - val_loss: 0.3643\n",
      "Epoch 456/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3861 - val_loss: 0.3659\n",
      "Epoch 457/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3827 - val_loss: 0.3639\n",
      "Epoch 458/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3871 - val_loss: 0.3730\n",
      "Epoch 459/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3834 - val_loss: 0.3634\n",
      "Epoch 460/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3836 - val_loss: 0.3691\n",
      "Epoch 461/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3833 - val_loss: 0.3682\n",
      "Epoch 462/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3816 - val_loss: 0.3592\n",
      "Epoch 463/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3817 - val_loss: 0.3776\n",
      "Epoch 464/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3864 - val_loss: 0.3652\n",
      "Epoch 465/2000\n",
      "177/177 [==============================] - 0s 40us/step - loss: 0.3865 - val_loss: 0.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/2000\n",
      "177/177 [==============================] - 0s 34us/step - loss: 0.3904 - val_loss: 0.3809\n",
      "Epoch 467/2000\n",
      "177/177 [==============================] - 0s 45us/step - loss: 0.3867 - val_loss: 0.3735\n",
      "Train on 59 samples, validate on 15 samples\n",
      "Epoch 1/2000\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2187.9912 - val_loss: 2035.2456\n",
      "Epoch 2/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2179.5801 - val_loss: 2025.8127\n",
      "Epoch 3/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2169.5583 - val_loss: 2015.3926\n",
      "Epoch 4/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 2158.3943 - val_loss: 2004.0909\n",
      "Epoch 5/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2146.1526 - val_loss: 1991.7898\n",
      "Epoch 6/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2132.8191 - val_loss: 1978.5104\n",
      "Epoch 7/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2118.5857 - val_loss: 1964.1726\n",
      "Epoch 8/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2103.1946 - val_loss: 1949.3958\n",
      "Epoch 9/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 2087.3389 - val_loss: 1933.9471\n",
      "Epoch 10/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2070.7463 - val_loss: 1917.5551\n",
      "Epoch 11/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2052.7229 - val_loss: 1899.2915\n",
      "Epoch 12/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2032.7979 - val_loss: 1879.8518\n",
      "Epoch 13/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 2011.9248 - val_loss: 1859.7859\n",
      "Epoch 14/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1990.4779 - val_loss: 1839.2196\n",
      "Epoch 15/2000\n",
      "59/59 [==============================] - 0s 69us/step - loss: 1968.4027 - val_loss: 1817.7399\n",
      "Epoch 16/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1945.0437 - val_loss: 1794.2123\n",
      "Epoch 17/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1919.4445 - val_loss: 1769.3260\n",
      "Epoch 18/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 1892.6829 - val_loss: 1743.7544\n",
      "Epoch 19/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1865.1871 - val_loss: 1717.0503\n",
      "Epoch 20/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1836.5050 - val_loss: 1689.5365\n",
      "Epoch 21/2000\n",
      "59/59 [==============================] - 0s 52us/step - loss: 1806.9926 - val_loss: 1661.5403\n",
      "Epoch 22/2000\n",
      "59/59 [==============================] - 0s 67us/step - loss: 1776.8876 - val_loss: 1632.4773\n",
      "Epoch 23/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1745.6842 - val_loss: 1602.7151\n",
      "Epoch 24/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1713.7096 - val_loss: 1571.9746\n",
      "Epoch 25/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 1680.6724 - val_loss: 1540.2466\n",
      "Epoch 26/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1646.5767 - val_loss: 1507.5386\n",
      "Epoch 27/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1611.4294 - val_loss: 1473.8589\n",
      "Epoch 28/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1575.2386 - val_loss: 1439.2177\n",
      "Epoch 29/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 1538.0138 - val_loss: 1403.6266\n",
      "Epoch 30/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1499.7665 - val_loss: 1367.1016\n",
      "Epoch 31/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1460.5143 - val_loss: 1329.6621\n",
      "Epoch 32/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1420.2795 - val_loss: 1291.3304\n",
      "Epoch 33/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1379.0865 - val_loss: 1252.1315\n",
      "Epoch 34/2000\n",
      "59/59 [==============================] - 0s 52us/step - loss: 1336.9642 - val_loss: 1212.0474\n",
      "Epoch 35/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1293.8546 - val_loss: 1170.9972\n",
      "Epoch 36/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1249.5404 - val_loss: 1128.7528\n",
      "Epoch 37/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1204.1293 - val_loss: 1086.1144\n",
      "Epoch 38/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1158.3440 - val_loss: 1042.2568\n",
      "Epoch 39/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1111.2578 - val_loss: 997.7293\n",
      "Epoch 40/2000\n",
      "59/59 [==============================] - 0s 84us/step - loss: 1063.4562 - val_loss: 953.0879\n",
      "Epoch 41/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1015.5421 - val_loss: 907.4573\n",
      "Epoch 42/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 966.5899 - val_loss: 861.4022\n",
      "Epoch 43/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 917.2029 - val_loss: 815.0397\n",
      "Epoch 44/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 867.4833 - val_loss: 769.4794\n",
      "Epoch 45/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 818.8237 - val_loss: 724.7195\n",
      "Epoch 46/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 770.7643 - val_loss: 679.9143\n",
      "Epoch 47/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 722.6566 - val_loss: 635.1694\n",
      "Epoch 48/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 674.6376 - val_loss: 590.6011\n",
      "Epoch 49/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 626.7828 - val_loss: 546.3495\n",
      "Epoch 50/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 579.2820 - val_loss: 502.5728\n",
      "Epoch 51/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 532.3114 - val_loss: 459.4981\n",
      "Epoch 52/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 486.0883 - val_loss: 417.2991\n",
      "Epoch 53/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 440.8204 - val_loss: 376.0733\n",
      "Epoch 54/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 396.7031 - val_loss: 336.0550\n",
      "Epoch 55/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 353.9294 - val_loss: 297.7824\n",
      "Epoch 56/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 313.0466 - val_loss: 260.8092\n",
      "Epoch 57/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 273.5879 - val_loss: 225.6793\n",
      "Epoch 58/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 236.1447 - val_loss: 192.6164\n",
      "Epoch 59/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 200.9832 - val_loss: 162.1141\n",
      "Epoch 60/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 168.5748 - val_loss: 133.8910\n",
      "Epoch 61/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 138.6445 - val_loss: 108.3445\n",
      "Epoch 62/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 111.6210 - val_loss: 85.6439\n",
      "Epoch 63/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 87.6126 - val_loss: 65.8322\n",
      "Epoch 64/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 66.7187 - val_loss: 49.0412\n",
      "Epoch 65/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 49.0970 - val_loss: 34.9902\n",
      "Epoch 66/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 34.4503 - val_loss: 23.7266\n",
      "Epoch 67/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 22.8182 - val_loss: 15.1094\n",
      "Epoch 68/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 14.0314 - val_loss: 8.9679\n",
      "Epoch 69/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 7.9061 - val_loss: 4.9744\n",
      "Epoch 70/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 4.0903 - val_loss: 2.8961\n",
      "Epoch 71/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 2.3324 - val_loss: 2.4141\n",
      "Epoch 72/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 2.2841 - val_loss: 3.1859\n",
      "Epoch 73/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 3.5724 - val_loss: 4.8744\n",
      "Epoch 74/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 5.8114 - val_loss: 7.1264\n",
      "Epoch 75/2000\n",
      "59/59 [==============================] - 0s 52us/step - loss: 8.6034 - val_loss: 9.5992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 11.5743 - val_loss: 11.9847\n",
      "Epoch 77/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 14.4001 - val_loss: 14.0392\n",
      "Epoch 78/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 16.8240 - val_loss: 15.6017\n",
      "Epoch 79/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 18.6694 - val_loss: 16.5754\n",
      "Epoch 80/2000\n",
      "59/59 [==============================] - 0s 85us/step - loss: 19.8254 - val_loss: 16.9381\n",
      "Epoch 81/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 20.2710 - val_loss: 16.7022\n",
      "Epoch 82/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 20.0271 - val_loss: 15.9367\n",
      "Epoch 83/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 19.1749 - val_loss: 14.5660\n",
      "Epoch 84/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 17.6029 - val_loss: 12.7390\n",
      "Epoch 85/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 15.4920 - val_loss: 10.6905\n",
      "Epoch 86/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 13.0972 - val_loss: 8.6225\n",
      "Epoch 87/2000\n",
      "59/59 [==============================] - 0s 52us/step - loss: 10.6531 - val_loss: 6.6772\n",
      "Epoch 88/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 8.3274 - val_loss: 4.9565\n",
      "Epoch 89/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 6.2373 - val_loss: 3.5302\n",
      "Epoch 90/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 4.4609 - val_loss: 2.4423\n",
      "Epoch 91/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 3.0503 - val_loss: 1.6890\n",
      "Epoch 92/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2.0063 - val_loss: 1.2564\n",
      "Epoch 93/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.3245 - val_loss: 1.1206\n",
      "Epoch 94/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.9706 - val_loss: 1.2630\n",
      "Epoch 95/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.9190 - val_loss: 1.5468\n",
      "Epoch 96/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.0609 - val_loss: 1.9263\n",
      "Epoch 97/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1.3344 - val_loss: 2.3334\n",
      "Epoch 98/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.6815 - val_loss: 2.7258\n",
      "Epoch 99/2000\n",
      "59/59 [==============================] - 0s 33us/step - loss: 2.0321 - val_loss: 3.0599\n",
      "Epoch 100/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2.3385 - val_loss: 3.3169\n",
      "Epoch 101/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 2.5781 - val_loss: 3.4710\n",
      "Epoch 102/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2.7265 - val_loss: 3.5165\n",
      "Epoch 103/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 2.7744 - val_loss: 3.4653\n",
      "Epoch 104/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 2.7289 - val_loss: 3.3388\n",
      "Epoch 105/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2.6085 - val_loss: 3.1555\n",
      "Epoch 106/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 2.4336 - val_loss: 2.9251\n",
      "Epoch 107/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 2.2198 - val_loss: 2.6600\n",
      "Epoch 108/2000\n",
      "59/59 [==============================] - 0s 67us/step - loss: 1.9846 - val_loss: 2.3805\n",
      "Epoch 109/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.7470 - val_loss: 2.1106\n",
      "Epoch 110/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 1.5253 - val_loss: 1.8638\n",
      "Epoch 111/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 1.3300 - val_loss: 1.6446\n",
      "Epoch 112/2000\n",
      "59/59 [==============================] - 0s 67us/step - loss: 1.1662 - val_loss: 1.4580\n",
      "Epoch 113/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.0384 - val_loss: 1.3086\n",
      "Epoch 114/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.9479 - val_loss: 1.1986\n",
      "Epoch 115/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8932 - val_loss: 1.1254\n",
      "Epoch 116/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8694 - val_loss: 1.0800\n",
      "Epoch 117/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8693 - val_loss: 1.0549\n",
      "Epoch 118/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8873 - val_loss: 1.0455\n",
      "Epoch 119/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9173 - val_loss: 1.0494\n",
      "Epoch 120/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.9529 - val_loss: 1.0617\n",
      "Epoch 121/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9874 - val_loss: 1.0763\n",
      "Epoch 122/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.0163 - val_loss: 1.0887\n",
      "Epoch 123/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 1.0370 - val_loss: 1.0972\n",
      "Epoch 124/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.0477 - val_loss: 1.1017\n",
      "Epoch 125/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 1.0477 - val_loss: 1.1021\n",
      "Epoch 126/2000\n",
      "59/59 [==============================] - 0s 52us/step - loss: 1.0380 - val_loss: 1.0982\n",
      "Epoch 127/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 1.0208 - val_loss: 1.0899\n",
      "Epoch 128/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9989 - val_loss: 1.0797\n",
      "Epoch 129/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9739 - val_loss: 1.0710\n",
      "Epoch 130/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9478 - val_loss: 1.0660\n",
      "Epoch 131/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.9223 - val_loss: 1.0648\n",
      "Epoch 132/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8992 - val_loss: 1.0670\n",
      "Epoch 133/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8794 - val_loss: 1.0731\n",
      "Epoch 134/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8637 - val_loss: 1.0834\n",
      "Epoch 135/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8523 - val_loss: 1.0972\n",
      "Epoch 136/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8454 - val_loss: 1.1121\n",
      "Epoch 137/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8425 - val_loss: 1.1262\n",
      "Epoch 138/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8426 - val_loss: 1.1394\n",
      "Epoch 139/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8449 - val_loss: 1.1524\n",
      "Epoch 140/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8485 - val_loss: 1.1646\n",
      "Epoch 141/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8527 - val_loss: 1.1746\n",
      "Epoch 142/2000\n",
      "59/59 [==============================] - 0s 84us/step - loss: 0.8566 - val_loss: 1.1817\n",
      "Epoch 143/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 0.8597 - val_loss: 1.1862\n",
      "Epoch 144/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8615 - val_loss: 1.1885\n",
      "Epoch 145/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8621 - val_loss: 1.1881\n",
      "Epoch 146/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8613 - val_loss: 1.1844\n",
      "Epoch 147/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8592 - val_loss: 1.1777\n",
      "Epoch 148/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8563 - val_loss: 1.1697\n",
      "Epoch 149/2000\n",
      "59/59 [==============================] - 0s 67us/step - loss: 0.8528 - val_loss: 1.1611\n",
      "Epoch 150/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8490 - val_loss: 1.1519\n",
      "Epoch 151/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 0.8452 - val_loss: 1.1422\n",
      "Epoch 152/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 0.8417 - val_loss: 1.1325\n",
      "Epoch 153/2000\n",
      "59/59 [==============================] - 0s 84us/step - loss: 0.8386 - val_loss: 1.1236\n",
      "Epoch 154/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8362 - val_loss: 1.1154\n",
      "Epoch 155/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8343 - val_loss: 1.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8331 - val_loss: 1.1003\n",
      "Epoch 157/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8324 - val_loss: 1.0939\n",
      "Epoch 158/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8321 - val_loss: 1.0889\n",
      "Epoch 159/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8322 - val_loss: 1.0851\n",
      "Epoch 160/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8324 - val_loss: 1.0821\n",
      "Epoch 161/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8326 - val_loss: 1.0796\n",
      "Epoch 162/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8327 - val_loss: 1.0779\n",
      "Epoch 163/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8326 - val_loss: 1.0769\n",
      "Epoch 164/2000\n",
      "59/59 [==============================] - 0s 34us/step - loss: 0.8323 - val_loss: 1.0762\n",
      "Epoch 165/2000\n",
      "59/59 [==============================] - 0s 68us/step - loss: 0.8318 - val_loss: 1.0755\n",
      "Epoch 166/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8311 - val_loss: 1.0753\n",
      "Epoch 167/2000\n",
      "59/59 [==============================] - 0s 51us/step - loss: 0.8304 - val_loss: 1.0757\n",
      "Epoch 168/2000\n",
      "59/59 [==============================] - 0s 50us/step - loss: 0.8295 - val_loss: 1.0768\n",
      "Train on 148 samples, validate on 74 samples\n",
      "Epoch 1/5000\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.5878 - val_loss: 0.2340 - val_accuracy: 0.8378\n",
      "Epoch 2/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.2455 - accuracy: 0.5541 - val_loss: 0.2228 - val_accuracy: 0.8919\n",
      "Epoch 3/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.2296 - accuracy: 0.7027 - val_loss: 0.1873 - val_accuracy: 0.8243\n",
      "Epoch 4/5000\n",
      "148/148 [==============================] - 0s 67us/step - loss: 0.2074 - accuracy: 0.7095 - val_loss: 0.1392 - val_accuracy: 0.8514\n",
      "Epoch 5/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.1801 - accuracy: 0.7838 - val_loss: 0.1582 - val_accuracy: 0.7568\n",
      "Epoch 6/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.1922 - accuracy: 0.7500 - val_loss: 0.1140 - val_accuracy: 0.9189\n",
      "Epoch 7/5000\n",
      "148/148 [==============================] - 0s 74us/step - loss: 0.1071 - accuracy: 0.9122 - val_loss: 0.0462 - val_accuracy: 0.9730\n",
      "Epoch 8/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0684 - accuracy: 0.9257 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 9/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.0742 - accuracy: 0.9189 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 10/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.1188 - accuracy: 0.8581 - val_loss: 0.0574 - val_accuracy: 0.9459\n",
      "Epoch 11/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.0952 - accuracy: 0.8986 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 12/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0908 - accuracy: 0.9054 - val_loss: 0.0302 - val_accuracy: 0.9865\n",
      "Epoch 13/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.0569 - accuracy: 0.9595 - val_loss: 0.0554 - val_accuracy: 0.9459\n",
      "Epoch 14/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0542 - accuracy: 0.9459 - val_loss: 0.0320 - val_accuracy: 0.9865\n",
      "Epoch 15/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.0672 - accuracy: 0.9392 - val_loss: 0.0537 - val_accuracy: 0.9595\n",
      "Epoch 16/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0576 - accuracy: 0.9459 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Train on 148 samples, validate on 74 samples\n",
      "Epoch 1/5000\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.5878 - val_loss: 0.2472 - val_accuracy: 0.4730\n",
      "Epoch 2/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.2407 - accuracy: 0.5878 - val_loss: 0.1944 - val_accuracy: 0.7432\n",
      "Epoch 3/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.2272 - accuracy: 0.7095 - val_loss: 0.2371 - val_accuracy: 0.4730\n",
      "Epoch 4/5000\n",
      "148/148 [==============================] - 0s 74us/step - loss: 0.2307 - accuracy: 0.5946 - val_loss: 0.1973 - val_accuracy: 0.9324\n",
      "Epoch 5/5000\n",
      "148/148 [==============================] - 0s 60us/step - loss: 0.1978 - accuracy: 0.8243 - val_loss: 0.1974 - val_accuracy: 0.6892\n",
      "Epoch 6/5000\n",
      "148/148 [==============================] - 0s 75us/step - loss: 0.2137 - accuracy: 0.7027 - val_loss: 0.3074 - val_accuracy: 0.4730\n",
      "Epoch 7/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.1950 - accuracy: 0.7770 - val_loss: 0.1477 - val_accuracy: 0.7568\n",
      "Epoch 8/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.2039 - accuracy: 0.6486 - val_loss: 0.1559 - val_accuracy: 0.9189\n",
      "Epoch 9/5000\n",
      "148/148 [==============================] - 0s 67us/step - loss: 0.1902 - accuracy: 0.7230 - val_loss: 0.1732 - val_accuracy: 0.7973\n",
      "Epoch 10/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.1509 - accuracy: 0.8919 - val_loss: 0.1163 - val_accuracy: 0.8378\n",
      "Epoch 11/5000\n",
      "148/148 [==============================] - 0s 74us/step - loss: 0.1545 - accuracy: 0.7703 - val_loss: 0.0986 - val_accuracy: 0.9730\n",
      "Epoch 12/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.1024 - accuracy: 0.9527 - val_loss: 0.0559 - val_accuracy: 0.9865\n",
      "Epoch 13/5000\n",
      "148/148 [==============================] - 0s 74us/step - loss: 0.0738 - accuracy: 0.9527 - val_loss: 0.0763 - val_accuracy: 0.8919\n",
      "Epoch 14/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.1301 - accuracy: 0.8176 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 15/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0872 - accuracy: 0.9054 - val_loss: 0.0777 - val_accuracy: 0.8784\n",
      "Epoch 16/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0979 - accuracy: 0.8784 - val_loss: 0.0436 - val_accuracy: 0.9459\n",
      "Epoch 17/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0712 - accuracy: 0.8986 - val_loss: 0.0493 - val_accuracy: 0.9459\n",
      "Epoch 18/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0569 - accuracy: 0.9257 - val_loss: 0.0327 - val_accuracy: 0.9730\n",
      "Epoch 19/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0472 - accuracy: 0.9459 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 20/5000\n",
      "148/148 [==============================] - 0s 68us/step - loss: 0.0347 - accuracy: 0.9865 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 21/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0334 - accuracy: 0.9865 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 22/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0292 - accuracy: 0.9932 - val_loss: 0.0303 - val_accuracy: 0.9730\n",
      "Epoch 23/5000\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.93 - 0s 54us/step - loss: 0.0332 - accuracy: 0.9595 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 24/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0277 - accuracy: 0.9797 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 25/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0245 - accuracy: 0.9865 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 26/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 27/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0400 - accuracy: 0.9459 - val_loss: 0.0433 - val_accuracy: 0.9459\n",
      "Epoch 28/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.1123 - accuracy: 0.8649 - val_loss: 0.0274 - val_accuracy: 0.9730\n",
      "Epoch 29/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0626 - accuracy: 0.9054 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 30/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0274 - accuracy: 0.9865 - val_loss: 0.0238 - val_accuracy: 0.9730\n",
      "Epoch 31/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 78us/step - loss: 0.0240 - accuracy: 0.9797 - val_loss: 0.0381 - val_accuracy: 0.9459\n",
      "Epoch 32/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0726 - accuracy: 0.8986 - val_loss: 0.0221 - val_accuracy: 0.9730\n",
      "Epoch 33/5000\n",
      "148/148 [==============================] - 0s 61us/step - loss: 0.0308 - accuracy: 0.9662 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 34/5000\n",
      "148/148 [==============================] - 0s 54us/step - loss: 0.0288 - accuracy: 0.9797 - val_loss: 0.0138 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "after_encoder_train = autoencoder(X_train)\n",
    "after_encoder_test = autoencoder(X_test)\n",
    "pred_non_AE = neural_network(X_train, y_train, X_test, y_test)\n",
    "pred_AE = neural_network(after_encoder_train, y_train, after_encoder_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder summery\n",
    "\n",
    "auto encoder is effect in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
